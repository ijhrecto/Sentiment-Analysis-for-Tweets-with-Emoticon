{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Tweets with Emojis\n",
    "This is method 2.\n",
    "Where we use a dataset contatining both utf-8 emoticons and tweets texts. We will be training it using naive bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data\n",
    "we will be importing the dataset that we processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emojis = pd.read_csv('dataset/15_emoticon_data.csv')\n",
    "df_tweets = pd.read_csv('dataset/1k_data_emoji_tweets_senti_posneg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Emoji</th>\n",
       "      <th>Unicode codepoint</th>\n",
       "      <th>Unicode name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>üòç</td>\n",
       "      <td>0x1f60d</td>\n",
       "      <td>SMILING FACE WITH HEART-SHAPED EYES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>üò≠</td>\n",
       "      <td>0x1f62d</td>\n",
       "      <td>LOUDLY CRYING FACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>üòò</td>\n",
       "      <td>0x1f618</td>\n",
       "      <td>FACE THROWING A KISS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>üòä</td>\n",
       "      <td>0x1f60a</td>\n",
       "      <td>SMILING FACE WITH SMILING EYES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>üòÅ</td>\n",
       "      <td>0x1f601</td>\n",
       "      <td>GRINNING FACE WITH SMILING EYES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>üòâ</td>\n",
       "      <td>0x1f609</td>\n",
       "      <td>WINKING FACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>üòÑ</td>\n",
       "      <td>0x1f604</td>\n",
       "      <td>SMILING FACE WITH OPEN MOUTH AND SMILING EYES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>üòí</td>\n",
       "      <td>0x1f612</td>\n",
       "      <td>UNAMUSED FACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>üòî</td>\n",
       "      <td>0x1f614</td>\n",
       "      <td>PENSIVE FACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>üò¢</td>\n",
       "      <td>0x1f622</td>\n",
       "      <td>CRYING FACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>üòÜ</td>\n",
       "      <td>0x1f606</td>\n",
       "      <td>SMILING FACE WITH OPEN MOUTH AND TIGHTLY-CLOSE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>üòÄ</td>\n",
       "      <td>0x1f600</td>\n",
       "      <td>GRINNING FACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>üòê</td>\n",
       "      <td>0x1f610</td>\n",
       "      <td>NEUTRAL FACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>üòõ</td>\n",
       "      <td>0x1f61b</td>\n",
       "      <td>FACE WITH STUCK-OUT TONGUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>üò≤</td>\n",
       "      <td>0x1f632</td>\n",
       "      <td>ASTONISHED FACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>üòß</td>\n",
       "      <td>0x1f627</td>\n",
       "      <td>ANGUISHED FACE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 Emoji Unicode codepoint  \\\n",
       "0            0     üòç           0x1f60d   \n",
       "1            1     üò≠           0x1f62d   \n",
       "2            2     üòò           0x1f618   \n",
       "3            3     üòä           0x1f60a   \n",
       "4            4     üòÅ           0x1f601   \n",
       "5            5     üòâ           0x1f609   \n",
       "6            6     üòÑ           0x1f604   \n",
       "7            7     üòí           0x1f612   \n",
       "8            8     üòî           0x1f614   \n",
       "9            9     üò¢           0x1f622   \n",
       "10          10     üòÜ           0x1f606   \n",
       "11          11     üòÄ           0x1f600   \n",
       "12          12     üòê           0x1f610   \n",
       "13          13     üòõ           0x1f61b   \n",
       "14          14     üò≤           0x1f632   \n",
       "15          15     üòß           0x1f627   \n",
       "\n",
       "                                         Unicode name  \n",
       "0                 SMILING FACE WITH HEART-SHAPED EYES  \n",
       "1                                  LOUDLY CRYING FACE  \n",
       "2                                FACE THROWING A KISS  \n",
       "3                      SMILING FACE WITH SMILING EYES  \n",
       "4                     GRINNING FACE WITH SMILING EYES  \n",
       "5                                        WINKING FACE  \n",
       "6       SMILING FACE WITH OPEN MOUTH AND SMILING EYES  \n",
       "7                                       UNAMUSED FACE  \n",
       "8                                        PENSIVE FACE  \n",
       "9                                         CRYING FACE  \n",
       "10  SMILING FACE WITH OPEN MOUTH AND TIGHTLY-CLOSE...  \n",
       "11                                      GRINNING FACE  \n",
       "12                                       NEUTRAL FACE  \n",
       "13                         FACE WITH STUCK-OUT TONGUE  \n",
       "14                                    ASTONISHED FACE  \n",
       "15                                     ANGUISHED FACE  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the emojis used in the 1k tweet data\n",
    "# does not have sentiment cause the naive bayes will assign the sentiment automatically\n",
    "df_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I just did happy.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yeah did update to 16.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Cleantha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Good luck to Rich riding for great project in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>but Genix deserves so much more than Myth! Ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>1</td>\n",
       "      <td>Nice gif üòä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>1</td>\n",
       "      <td>Thanks for sharing my iris photo. I really app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh no üòß</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>1</td>\n",
       "      <td>Do you want me to follow you back? If you do t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>Ok will do! I never had any problems with the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  sentiment                                               post\n",
       "0             0          1                                 I just did happy.1\n",
       "1             1          0                           Yeah did update to 16.04\n",
       "2             2          0                                           Cleantha\n",
       "3             3          1  Good luck to Rich riding for great project in ...\n",
       "4             4          1  but Genix deserves so much more than Myth! Ope...\n",
       "..          ...        ...                                                ...\n",
       "995         995          1                                         Nice gif üòä\n",
       "996         996          1  Thanks for sharing my iris photo. I really app...\n",
       "997         997          0                                            Oh no üòß\n",
       "998         998          1  Do you want me to follow you back? If you do t...\n",
       "999         999          0  Ok will do! I never had any problems with the ...\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Methods for Sentiment Analysis:\n",
    "1. this is method 2, simply using naive bayes to train the dataset\n",
    "    - pros : easiest to do, just focus on the naive bayes(NB) classifier, less preprocessing\n",
    "    - cons : the sentiments of emojis might not be accurate since it is based on the analysis of the given data to the NB classifier\n",
    "    \n",
    "2. another method, converting the emoticons to words first, before training the data\n",
    "    - pros : adds more vocabulary to the NB classifier, might have better sentiment analysis\n",
    "    - cons : additional data preprocessing, plus the cons of method above\n",
    "    \n",
    "3. can use the old method (method 1), separate text and emoji\n",
    "    - pros : emoji sentiment is based on the emoji data, thus will not be affected by the NB classifier\n",
    "    - cons : emoji sentiment might strongly affect the sentiment analysis (more emoji == less text sentiment influence). More data processing cause of text and symbol separation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF vectorizer\n",
    "stopset = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(use_idf=True, lowercase=True,\n",
    "                            strip_accents='ascii', stop_words=stopset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets2 = df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000, 2108)\n",
      "1000 observations X 2108 unique words\n"
     ]
    }
   ],
   "source": [
    "# dependent variable will be linked as:\n",
    "# 0 = negative, 1 = positive\n",
    "y = df_tweets2.sentiment\n",
    "# convert 'sentence' from text to features\n",
    "X = vectorizer.fit_transform(df_tweets2.post)\n",
    "\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "print(f'{X.shape[0]} observations X {X.shape[1]} unique words')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7425523736305978"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Train Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=None)\n",
    "\n",
    "# we will train a naive bayes classifier\n",
    "clf = naive_bayes.MultinomialNB()\n",
    "# clf = naive_bayes.BernoulliNB()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# test our models accuracy\n",
    "roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build tweet sentiment analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def get_sentiment(s_input = 'üòç I love sentiment analysis üòä'):\n",
    "    # turn input into array\n",
    "    input_array= np.array([s_input])\n",
    "    # vectorize the input\n",
    "    input_vector = vectorizer.transform(input_array)\n",
    "    # predict the score of vector\n",
    "    pred_senti = clf.predict(input_vector)\n",
    "\n",
    "    return pred_senti[0]\n",
    "print(get_sentiment())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_senti_status(test):\n",
    "    print('========================================')\n",
    "    print(f'Your input is \"{test}\" \\n')\n",
    "    sentiment = get_sentiment(test)\n",
    "    sentiment = 'Positive' if sentiment == 1 else 'Negative'\n",
    "    print(f'\\nYour input is of \"{sentiment}\" sentiment'.upper())\n",
    "    print('========================================')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòç I love sentiment analysis üòä\n"
     ]
    }
   ],
   "source": [
    "# for text area\n",
    "l = widgets.Layout(flex='0 1 auto', height='50px',width='auto')\n",
    "post_tweet = widgets.Textarea(value='üòç I love sentiment analysis üòä', layout=l)\n",
    "print(post_tweet.value)\n",
    "# for button\n",
    "button = widgets.Button(description=\"Say your Sentiments!\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_tweet_clicked(b):\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        output.layout={'border': '1px solid black'}\n",
    "        print_senti_status(post_tweet.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4a977d587347a6b2e4cb6773a2cf12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='üòç I love sentiment analysis üòä', layout=Layout(flex='0 1 auto', height='50px', width='auto'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62556f1aa5b54909bba292efc5294f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Say your Sentiments!', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858881af26c644afbcb57def8d0f7269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# type post below\n",
    "display(post_tweet,button, output)\n",
    "button.on_click(on_tweet_clicked)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01126bec2af240dbbef20c43e62ee338": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "08f7ad18d03045a38291679244e628de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "border": "1px solid black"
      }
     },
     "2be717dc16e3409f9d03188453b31016": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Say your Sentiments!",
       "layout": "IPY_MODEL_01126bec2af240dbbef20c43e62ee338",
       "style": "IPY_MODEL_635f418e5dda4d3c923e6a78c90ae8b5"
      }
     },
     "635f418e5dda4d3c923e6a78c90ae8b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "6bd9d0aa1d3643f68a1957a44f057b0f": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_08f7ad18d03045a38291679244e628de",
       "outputs": [
        {
         "name": "stdout",
         "output_type": "stream",
         "text": "========================================\nYour input is \"üòç I love sentiment analysis üòä\" \n\n\nYOUR INPUT IS OF \"POSITIVE\" SENTIMENT\n========================================\n"
        }
       ]
      }
     },
     "a2dfb9c3644443b38b1d7df425137407": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "aec549cb2b5e42c193064abc32c8353b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "0 1 auto",
       "height": "50px",
       "width": "auto"
      }
     },
     "c4d27f9bb4b1452993c10f291fcc5c80": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ce9d51322ec448e18dd6ede085b9aeb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "TextareaModel",
      "state": {
       "layout": "IPY_MODEL_aec549cb2b5e42c193064abc32c8353b",
       "style": "IPY_MODEL_a2dfb9c3644443b38b1d7df425137407",
       "value": "üòç I love sentiment analysis üòä"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
